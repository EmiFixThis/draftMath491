\section{Semantic Security: Defining Security with Games} 

Semantic Security was a game proposed by Goldwasser and Micali in their 1982 paper entitled: \textit{`Probabilistic Encryption \& How to Play Mental Poker Keeping Secret All Partial Information'}\cite{Gol1982}, in response to papers from Rivest, Shamir, Adelman, \cite{Riv1978} and Rabin \cite{Rab1979} detailing the theory behind the Diffie-Hellman based RSA cryptosystem. 

Goldwasser and Micali's intention was to strengthen the security assumptions of Diffie-Hellman based cryptosystems by formally defining what it would mean for such systems to be called secure. 


\subsection{Goldwasser \& Micali's: Mental Poker and Partial Information} 


[\cite{Gol1982}] Proposed the following property for any implementation of a Diffie-Hellman public-key cryptosystem:  

\medskip

\begin{prot}
	`An adversary, who knows the encryption of an algorithm and is given the ciphertext, cannot obtain any information about the cleartext.'
\end{prot}\cite{Gol1982}


Informally, the above property states that a given cryptographic scheme is considered insecure, if given some of the ciphertext (but not the private key), it is possible for an adversary to recover \emph{any} information about the plaintext, or if the adversary can recover useful information about the plaintext of the message, by some manipulation of the ciphertext in a reasonable amount of time (feasibly). 



\subsection{Weaknesses in the Assumptions of RSA} 


Goldwasser and Micali pointed out that the security assumptions given in \cite{Rab1979} and \cite{Riv1978} had some particularly significant drawbacks. The original construction of RSA was unpadded, only relied on a random choices for messages. 

\bigskip

\begin{asu}
    There exists a \gls{trapdoor function} $f(x)$ that is easily computed, while $x$ is not easily computed from $f(x)$ (unless some additional information is known). 
    To encrypt any message $m$, you evaluate $f$ at $m$, and receive the ciphertext $f(m)$.
\end{asu}


This first assumption gives us the following objection and cases.

\smallskip

\begin{ojj}
 If the inverse of $f$ has some specialized form, or some additional structure, simply assuming that $f(x)$ is assumed to be a trapdoor function does not guarantee that $x$ cannot be easily computed when this additional information is not known. 
\end{ojj}
\smallskip


\begin{case}
First, messages do not typically consists of randomly chosen numbers, they have more structure.
\end{case}
\smallskip

\smallskip

\begin{case}
Second, the additional structure these messages possess may assist in decoding the ciphertext.
\end{case} 

\medskip


\begin{exmp}
	Compare two functions $f(m)$ and $g(n)$, where the input $m$ for $f$ is some random ASCII sequence, and the input $n$ for $g$ is an ASCII sequence which represents sentences written in English. Then it may happen that $m$ is hard to recover from $f(m)$, but that $n$ is easy to recover from $g(n)$.
\end{exmp}

\medskip

\begin{rem}
	Even if we assume that $f$ is a trapdoor function, that does not negate the possibility that the message or even half the message may not be recoverable from $f(x)$. 
\end{rem}

\bigskip

Concerning the use of trapdoors in general:

\begin{center}
\begin{quotation}
    `Covering ones face with a handkerchief 
    certainly helps to hide personal identity. 
    
    However: it will not hide from me 
    the identity of a special subset of people:
    my mother, my sister, close friends.
        
    I can gather a lot of information 
    about people I cannot identify: 
    their height, their hair color, and so on.'
    	$\sym$\cite{Gold1982}
\end{quotation}
\end{center}

\bigskip


These facts about the use of a handkerchief are exactly those you would find issue with in using any public-key cryptosystem whose security relied solely on trapdoors. In fact, they are the same arguments which arise as problems in cases one and two. 

\bigskip
In order to better understand how this analogy can provide a better definition for the security of a cryptosystem, Goldwasser and Micali switch RSA from using only a randomly chosen message the set of all possible messages in the message space. 

\medskip

\begin{cla}
    If the set of messages $\mathcal{M}$ is sparse in $\mathbb{Z}_{N}^{\ast}$, then the ability to correctly recover even 1\% of all messages is not possible for a random polynomial time algorithm in the case of factoring.
\end{cla}

\medskip

\emph{Sparse} in this context means that when $x \in \mathbb{Z}_{N}^{*}$ is chosen randomly, we have a probability of any $x$ chosen being a message is for all intents and purposes zero. 

\medskip

The requirement that the messagespace should be sparse means that encoding a message does not simply rely on the content of the message but also the outcome of a sequence of fair coin tosses. The addition of the coin toss outcomes expands the size of the number of possible encodings of a message, where each possible encoding remains unique. 

\bigskip

Second, they define the notion of secure for any public-key cryptosystem in a way that disallows the use of trapdoor functions:

\bigskip

\begin{defn}{Insecurity. }
	Let $\mathcal{P} \subset \mathcal{M}$  be an arbitrary decision problem which is easy to calculate, and let $m \in \mathcal{M}$. If an adversary has the encrypted form of $m$ and is able to calculate $\mathcal{P}(m)$, then the adversary can obtain \emph{some} information about $m$ from its ciphertext.
\end{defn}

\bigskip

The first given definition is necessary but it is not sufficient.

\smallskip

RSA defined purely in terms of trapdoors is deterministic. Meaning, if an adversary has some amount of ciphertext and can calculate $\mathcal{P}$, then they might be able to just guess the message $m$. 

\medskip

However, if $\mathcal{M}$ is an appropriate uniform distribution then calculating $\mathcal{P}(m)$ if now phrased in terms of a probability. This addition to the randomization, strengthens the notion of semantic security and gives us the following stronger notion of security.

\medskip

\begin{defn}{Semantic Security}
    Let $\varepsilon$ be the advantage ascribed to an adversary in solving $\mathcal{P}$. If the adversary has a probability greater than $p + \varepsilon$ of solving $\mathcal{P}$ then we should consider the system insecure. 
\end{defn}

\medskip

In other words, a cryptosystem is secure if an adversary cannot \emph{feasibly} gain any information about the plaintext by manipulating the ciphertext. 

\medskip

\begin{defn}{Perfect Secrecy (Shannon). }
	If an adversary in possession of some ciphertext cannot gain any additional information about the plaintext (message), then we call the cryptosystem \emph{perfectly secure}.
\end{defn}

\medskip

In \cite{Gol1982} the definition of semantic security is a slightly weaker form of Shannon's \emph{perfect secrecy}. The key difference is that semantic security relaxes the restriction by Shannon from if an adversary cannot gain \emph{any} information about the message, to the adversary cannot gain any information about the message \emph{feasibly}. 

\medskip


\[\text{semantic security} \overset{\mathcal{A}(c)}{\longrightarrow} \mathcal{M} \] 

\[\text{perfect secrecy} \overset{\mathcal{A}(c)}{\not \longrightarrow} \mathcal{M} \]


Another noticeable feature of semantic security is that it only can be applied to \emph{passive adversaries}, i.e. adversaries which may generate and study ciphertexts from some public key. It does not apply to the case where the adversary may request a decryption of chosen ciphertexts\footnote{It also does not apply to cases in which someone encrypts their own key, i.e., circular security.}. 

Given these (and a few unrelated) reasons it becomes evident that semantic security is an insufficient condition for ensuring the security of a cryptosystem. 
However, semantic security provides a bound on the minimum amount of security a cryptosystem should be able to provide. 


\bigskip

\subsection{`Provable' Security} 


It is not difficult to understand why an object may need to be formally defined before more work can proceed, particularly in the case of more abstract concepts such as security.

\medskip

\begin{exmp}
    Take for example the concept of safety in the context of bridge construction. It is easy to spot the case where the bridge is definitely not safe. 
    
    That's the case where a person who entered the bridge did not arrive at the other side (or perhaps at all) by continuing to use the bridge, i.e., the bridge failed. 
    
    It is much harder to consider all the cases where a trip over the bridge might range between perfectly safe to not at all. 
    
    There might be many cases where the person arrived at the other side of the bridge but not entirely safely.
    
    In some cases it will be the fault of the bridge, in other cases it may be other travelers, and in some cases it might be the person themself.
    
    However, it is clear for any case other than bridge failure we may claim the trip was safe. Clearly we need contextually related definitions for the notion of safe in the case of crossing bridges.
\end{exmp}


\bigskip

In the same way, it is necessary for there to be contextually relevant notions of security, it is also necessary that these notions be quantifiable in someway in order to build safe guards against insecurities. 

\medskip

In cryptography we use the method of \emph{security reduction}, or proof to determine the level of security a given cryptosystem imparts. This reduction is accomplished in many way but in general the process is as follows:
\smallskip

\begin{itemize}
   \item Remove all cases where the system is found insecure due to side channel or implementation fault based attacks\footnote{Usually these cases either cannot be accurately modeled or are specific to the implementation.}.
    \item Define the capabilities of the adversary (adversarial model).
    \item Define what level of access the adversary is assumed to have.
    \item Define the level of computational resources you may assume the adversary has at their disposal.
    \item State the computational hardness of the mathematical problem your scheme will base its security upon (why is it an appropriate choice?)
    \item If you can then state the security requirements of your scheme formally and prove the hardness of the mathematical problem is by the given assumptions on the adversary infeasible, you have `proved' your scheme.
    \item Alternatively, if you can find a scheme similar to your own whose hardness has already been proven, you may be able to reduce the proof of your systems hardness on some case where the other has been shown to hold.
    \item It might be then possible to state that assuming the hardness of the other problem your problem is at most as hard (or at least) as the other problem.
\end{itemize}




\subsubsection{Mathematical Proofs vs. Security Proofs}

It is important to understand that a mathematical proof and a security proof are not the same kinds of animals. While a mathematical proof gives an absolute assurance of some objects existence, properties, or some other notion. A `proof' of security does not offer come with any such resolve due to its reliance of the hardness or intractability of a given mathematical problem. 


One should not make the mistake in thinking a certain cryptographic scheme is equivalent to the intractability its corresponding mathematical problem. 

The relationship between the security of a system and it's corresponding underlying problem is not at all bidirectional. 

Specifically, if $\mathcal{P}$ is some intractable problem serving as a basis for a cryptosystem $\mathcal{S}$. The intractable property of $\mathcal{P}$ is not a sufficient condition to ensure the security of $\mathcal{S}$. 

\bigskip

\begin{exmp}
    
    The RSA algorithm's method of encryption uses modular exponentiation by some fixed prime, this function has a corresponding inverse which decomposes the modulus into its prime factors. The decryption algorithm of RSA takes advantage of the existence of its inverse. 
\smallskip
    However, it has never been proven that factoring the modulus is the only way or even the best way to decrypt the messages encoded by the modular exponentiation function. 
\smallskip
    We assume that solving the underlying problem of RSA is equivalent to factorization, but this may not be true at all. 
\smallskip
    In fact there have been results on both sides of the argument in many papers. If we consider \cite{Bon1998}, then we have a result which implies that the fixed prime which serves as the exponent for RSA may be a much easier way of breaking RSA than attempting to decompose it into prime factors. If we consider \cite{Bro2005}, we might have an implication that RSA is equivalent to factorization. 

\medskip 
However, the cases we choose to compare may have no relation on at all to the situation that really might exist. 
\end{exmp}

It would seem that it might be worth investigating if the questions of equivalency to factorization are the right type of questions to ask in this case, at all.
    