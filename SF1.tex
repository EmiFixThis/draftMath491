\section{Lattice-based Cryptography (LBC)} 

Lattice-based Cryptosystems are a subclass of Post-quantum cryptosystems. All modern cryptosystems require a minimum level of \emph{average-case complexity} (or \emph{intractability}); meaning the mathematical problem(s) serving as a basis for the system are chosen at random from an appropriate probability distribution, with an assurance that any problem drawn from this distribution will almost probably \todo[inline]{check if you used almost-probably in the correct sense.} be hard to solve. 




 

\subsection{Average-case to Worst-case Connectivity}

In modern (hearafter refered to as classical) cryptography the problems which serve as mathematical basis for the construction are efficiently \footnote{Efficient in this context means algorithmically solvable in polynomial time.} solved by quantum algorithms. The first proof of the solvability of the problems for RSA and the Diffie-Hellman protocols was given by Peter Shor in 1997 [\cite{Sho19970}] 

The definition of worst-case as discussed in lattice-based cryptography is quite different than the traditional form used in the field of Theoretical Computer Science (TCS). For most applications in cryptography the worst-case was not very useful at all, the worst-case simply meant that there existed hard to solve instances of a problem which applied under the worst-case solvability constraints. In fact, many problems which would seem to be hard to solve in the worst-case instances, would ironically turn out to be easily solvable on the average. This would often be true in cryptography, where secret keys would produce instances with added structure [\cite{Pei20151}].  


For the most part, applied cryptographers did not need to worry too much about worst-case instances of problems. One might run a quick analysis of these instances to see if any vulnerabilities could be spotted, and perhaps eliminated, but overall they were ignored (sometimes mocked, particularly by applied students poking at theoretical ones). 